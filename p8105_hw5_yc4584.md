p8105_hw5_yc4584
================
Yingyu Cui
2024-11-10

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
set.seed(1)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

## write a function for duplicated birthdays

``` r
duplicated_birthday = function(n){
  birthdays = sample(1:365, n, replace = TRUE)
  
  return(any(duplicated(birthdays)))
}
```

## then we run this 10000 times for number 2:50 and calculate the probability of duplicated birthdays

``` r
sim_birthday_results = 
  expand_grid(
    group_size = c(2:50),
    iter = 1:10000
  ) |> 
  mutate(
    results = map_lgl(group_size, duplicated_birthday)
  ) |> 
  group_by(group_size) |>
  summarize(
    prob = mean(results)
  )

sim_birthday_results
```

    ## # A tibble: 49 × 2
    ##    group_size   prob
    ##         <int>  <dbl>
    ##  1          2 0.0024
    ##  2          3 0.0085
    ##  3          4 0.0167
    ##  4          5 0.0267
    ##  5          6 0.0399
    ##  6          7 0.0521
    ##  7          8 0.0751
    ##  8          9 0.0925
    ##  9         10 0.116 
    ## 10         11 0.139 
    ## # ℹ 39 more rows

## then we make a plot showing the probability as a function of group size

``` r
birth_duplicated_plot =
  ggplot(sim_birthday_results, aes(x = group_size, y = prob)) +
  geom_point() +
  geom_line() +
  labs(
    x = "Group Size",
    y = "Probability of Duplicated Birthdays",
    title = "Probability of Duplicated Birthdays by Group Size"
  )

birth_duplicated_plot
```

<img src="p8105_hw5_yc4584_files/figure-gfm/plot1-1.png" width="90%" />

Here is the comment: The plot shows the probability of duplicated
birthdays by group size. The probability increases as the group size
increases. When the group size is 23, the probability of duplicated
birthdays is 0.5. This examines the birthday paradox, which states that
in a group of 23 people, there is a 50% chance that two people share the
same birthday, and when the group size is 50, the probability is close
to 1.

# Problem 2

## when μ=0, first we establish a function for the result of the t-test

``` r
t_test_result = function(n, mu){
  x = rnorm(n, mean = mu, sd = 5)
  
  t_test = t.test(x, mu = 0, conf.level = 0.95)
  
  tidy_result = t_test |> 
    broom::tidy()
  
  mean = tidy_result$estimate
  p_value = tidy_result$p.value
  
  tibble(mean = mean, 
         p_value = p_value)
}
```

## Now we obtain a data frame with the results of 5000 t-tests

``` r
sim_t_test_results = 
  expand_grid(
    n = 30,
    mu = 0,
    iter = 1:5000
  ) |> 
  mutate(
   results = map2(n, mu, t_test_result)
  ) |> 
  unnest(results)
```

## now I will repeat the above steps for μ=1:6

``` r
sim_t_test_results_1_6 = 
  expand_grid(
    n = 30,
    mu = c(1, 2, 3, 4, 5, 6),
    iter = 1:5000
  ) |> 
  mutate(
    results = map2(n, mu, t_test_result)
  ) |> 
  unnest(results)
```

## Make a plot showing the association of power and different values of μ

``` r
# first we calculate the power
sim_t_test_results_all = 
  bind_rows(sim_t_test_results, sim_t_test_results_1_6)

power_results = 
  sim_t_test_results_all |> 
  group_by(mu) |> 
  summarize(
    power = mean(p_value < 0.05)
  )

power_plot =
  ggplot(power_results, aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = 0:6) +
  labs(
    x = "True Mean (μ)",
    y = "Power (Proportion of Null Rejected)",
    title = "Power of the Test as a Function of Effect Size (μ)"
  )

power_plot
```

<img src="p8105_hw5_yc4584_files/figure-gfm/plot of power and mu-1.png" width="90%" />

Comment on the plot: The plot shows that the stronger effect size (which
is the more mu is away from 0) is, the higher the power of the test is
and the more likely the test is to correctly reject the null hypothesis.
When the true mean is 0, the power is the lowest, which is around 0.05.
When the true mean is 6, the power is the highest, which is around 1.

## Make one overlapping plots, blue one is showing the average estimate of μ^ on the y axis and the true value of μ on the x axis; the red one is the average estimate of μ^ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis.

``` r
# first calculate the average estimate of μ^ for two plots
mean_results = 
  sim_t_test_results_all |> 
  group_by(mu) |> 
  summarize(
    avg_estimate_all = mean(mean),
    avg_estimate_rejected = mean(mean[p_value < 0.05])
  ) |> 
  pivot_longer(
    cols = c(avg_estimate_all, avg_estimate_rejected),
    names_to = "type",
    values_to = "avg_estimate"
  ) |> 
  mutate(type = recode(type, 
                        avg_estimate_all = "All Samples", 
                        avg_estimate_rejected = "Rejected Samples"))

# Now I will make an overlapping plot
comparison_plot = 
  ggplot(mean_results, aes(x = mu, y = avg_estimate, color = type)) +
  geom_line() +
  geom_point() +
  labs(
    x = "True Mean (μ)",
    y = "Average Estimate of μ^",
    title = "Average Estimate of μ^ for All Samples and Only Rejected Samples",
    color = "Type"
  ) +
  scale_x_continuous(breaks = 0:6) +
  scale_color_manual(values = c("All Samples" = "blue", "Rejected Samples" = "red"))
  

comparison_plot
```

<img src="p8105_hw5_yc4584_files/figure-gfm/two plots-1.png" width="90%" />

comment on the plot: the sample average of μ^ across tests for which the
null is rejected is not approximately equal to the true value of μ. This
is because in the samples that the null is rejected, the samples tend to
have a larger effect size and also more likely to reject the null
hypothesis, which could skewed the average of μ^ upwards in these
samples. And this is the reason why the average estimate of μ^ is larger
than the true value of μ. However, when the true mean is more away from
0, the average estimate of μ^ is closer to the true value of μ. This is
because in these sample, there is a higher power of the test, which
means the proportion of test rejected is higher, and the average
estimate of μ^ is more likely to be closer to the true value of μ.
